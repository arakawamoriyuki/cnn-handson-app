{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_texts = ['犬', '猫']\n",
    "datasets_path = 'volume/images'\n",
    "model_path = 'volume/models/model.h5'\n",
    "image_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = requests.get('https://github.com/trending?since=monthly').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "element = soup.select('ol.repo-list > li h3 a')[0]\n",
    "print(element.text)\n",
    "print('https://github.com{}'.format(element.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_scraping(search_texts=[], save_path='.', page=1):\n",
    "    for search_index, search_text in enumerate(search_texts):\n",
    "        \n",
    "        # googleで画像検索\n",
    "        url = 'https://www.google.co.jp/search?q={}&tbm=isch'.format(search_text)\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        for page_index in range(page):\n",
    "            \n",
    "            # 画像を拾う\n",
    "            image_elements = soup.select('#ires a > img')\n",
    "            for element_index, image_element in enumerate(image_elements):\n",
    "                \n",
    "                # src属性から画像をダウンロード\n",
    "                image_url = image_element.attrs['src']\n",
    "                response = requests.get(image_url, stream=True)\n",
    "                dest_path = '{}/{}'.format(save_path, search_index)\n",
    "                if not os.path.isdir(dest_path):\n",
    "                    os.makedirs(dest_path)\n",
    "                file_path = '{}/{}.png'.format(dest_path, (page_index * len(image_elements)) + element_index)\n",
    "                if response.status_code == 200:\n",
    "                    with open(file_path, 'wb') as file:\n",
    "                        response.raw.decode_content = True\n",
    "                        shutil.copyfileobj(response.raw, file)\n",
    "                        print('download: {}'.format(file_path))\n",
    "                        \n",
    "            # 次のページ\n",
    "            page_links = soup.select('#nav tr td a')\n",
    "            next_url = 'https://www.google.co.jp{}'.format(page_links[-1].attrs['href'])\n",
    "            html = requests.get(next_url).text\n",
    "            soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_scraping(search_texts=search_texts, save_path=datasets_path, page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dirs(src_path):\n",
    "    listdir = os.listdir(src_path)\n",
    "    return [path for path in listdir if os.path.isdir(os.path.join(src_path, path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_dirs(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_resize(src_path, size=28):\n",
    "    dirs = get_dirs(src_path)\n",
    "    for dir_path in dirs:\n",
    "        for image_path in glob.glob('{}/{}/**/*.*'.format(src_path, dir_path), recursive=True):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (size, size))\n",
    "            file_name = os.path.basename(image_path)\n",
    "            save_path = '{}/{}/{}'.format(src_path, dir_path, file_name)\n",
    "            cv2.imwrite(save_path, image)\n",
    "            print('resize: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_resize(datasets_path, size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, imghdr, time\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generate(src_path, rate=10):\n",
    "    datagen = ImageDataGenerator(\n",
    "        # rotation_range=40, #z軸回転\n",
    "        width_shift_range=0.05, #水平\n",
    "        height_shift_range=0.05, #上下\n",
    "        # shear_range=0.1, #斜め引き伸ばし\n",
    "        zoom_range=0.1, #ズーム\n",
    "        # horizontal_flip=True, #x軸回転\n",
    "        vertical_flip=True, #y軸回転\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    for image_path in glob.glob('{}/**/*.*'.format(src_path), recursive=True):\n",
    "        img = load_img(image_path)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "        generator = datagen.flow(\n",
    "            x,\n",
    "            batch_size=1,\n",
    "            save_to_dir=src_path,\n",
    "            save_prefix='gen',\n",
    "            save_format='png'\n",
    "        )\n",
    "        for _ in range(rate):\n",
    "            generator.next()\n",
    "        print('generate: {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dir_name in get_dirs(datasets_path):\n",
    "    target_path = '{}/{}'.format(datasets_path, dir_name)\n",
    "    image_generate(target_path, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# doc=(uniq) (mono sepi) (dcgan)\n",
    "# インポートの違い\n",
    "#   from tensorflow import keras\n",
    "#   from tensorflow.python.keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, imghdr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adadelta\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "from tensorflow.python.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.contrib.learn.python.learn.estimators._sklearn import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('volume/images/0/0.png')\n",
    "# 正規化 約分のようなもの 0~1などに正規化する\n",
    "normalized_image = image.astype(np.float32) / 255.0\n",
    "print(normalized_image)\n",
    "print(normalized_image.shape)\n",
    "# モデルによってはデータをベクトル化して1次元配列にすることもある\n",
    "vectorize_image = normalized_image.flatten()\n",
    "print(vectorize_image)\n",
    "print(vectorize_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_image(image_path, image_size=56):\n",
    "    \"\"\" 画像を正規化する\n",
    "    @param\n",
    "        images_path         画像パス\n",
    "        image_size          画像の1辺のpixel数\n",
    "    @return\n",
    "        normalized_image    正規化された画像\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (image_size, image_size))\n",
    "    normalized_image = image.astype(np.float32) / 255.0\n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot表現について\n",
    "# train_test_splitについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datasets(datasets_path, test_size=0.1, image_size=56):\n",
    "    \"\"\" 学習用データセットを返す\n",
    "    @param\n",
    "        datasets_path       分類名のフォルダに画像が格納されたデータセットのpath\n",
    "        test_size           テストに使用する画像の割合\n",
    "        image_size          画像サイズ\n",
    "    @return\n",
    "        datasets            tuple(train_images, test_images, train_labels, test_labels)\n",
    "    \"\"\"\n",
    "\n",
    "    labels = get_dirs(datasets_path)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for label in labels:\n",
    "        for image_path in glob.glob('{}/{}/**/*.*'.format(datasets_path, label), recursive=True):\n",
    "            # 画像形式でなければスキップ\n",
    "            if imghdr.what(image_path) is None:\n",
    "                continue\n",
    "\n",
    "            # 正規化したデータをxへ\n",
    "            normalized_image = get_normalized_image(image_path, image_size=image_size)\n",
    "            x.append(normalized_image)\n",
    "\n",
    "            # one hot表現答えラベルをyへ\n",
    "            one_hot = np.zeros(len(labels))\n",
    "            one_hot.put(labels.index(label), 1)\n",
    "            y.append(one_hot)\n",
    "\n",
    "    datasets = train_test_split(\n",
    "        np.array(x),\n",
    "        np.array(y),\n",
    "        test_size=test_size\n",
    "    )\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = get_datasets(datasets_path, test_size=0.1, image_size=image_size)\n",
    "train_images, test_images, train_labels, test_labels = datasets\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(num_classes, image_size=56, channels=3):\n",
    "    model = Sequential()\n",
    "\n",
    "    input_shape = (image_size, image_size, channels)\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    print(model.input_shape)\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNNについてhttps://i.stack.imgur.com/jNKSJ.png\n",
    "#   畳み込み 指定サイズごとに切り出してスライド、そのマッチングを元に増やす\n",
    "#   プーリング 強い特徴のみ残して減らす\n",
    "#   ドロップアウト ニューラルネットワークの線を学習ごとにランダムに切る(過学習抑制) ランダムにできる複数のモデルで学習したような平均化する効果があり、極端にフィットしてしまう事を防ぐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# なぜ一気に(None, 28, 28, 3)を(None, 2)にしないのか\n",
    "# https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch02/xor_gate.py\n",
    "# xorを作る為\n",
    "\n",
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-0.5, -0.5])\n",
    "    b = 0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1, x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y\n",
    "\n",
    "# NANDノードとORノードから受け取った値をANDノードが受け取るとXOR回路ができる\n",
    "# 層が少ないと(1層だと確実に)ANDとNANDとOR回路しか作れない\n",
    "\n",
    "# なぜXOR回路が必要なのか\n",
    "# http://hokuts.com/2015/12/04/ml3-mlp/\n",
    "# ANDとNANDとOR回路のみ(単純パーセプトロン)だと決定境界を線形でしか作れない\n",
    "# XORに分布したデータに対して単純パーセプトロンで解決できない問題があるから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = get_dirs(datasets_path)\n",
    "num_classes = len(labels)\n",
    "channels = 3\n",
    "model = create_model(num_classes, image_size=image_size, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create model image (tensorflow 1.4.0だと動かない)\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(datasets_path, model_path, image_size=56, channels=3, test_size=0.1, batch_size=1000, epochs=10):\n",
    "\n",
    "    datasets = get_datasets(datasets_path, test_size=test_size, image_size=image_size)\n",
    "    labels = get_dirs(datasets_path)\n",
    "    num_classes = len(labels)\n",
    "    train_images, test_images, train_labels, test_labels = datasets\n",
    "\n",
    "    model = load_model(model_path) if os.path.isfile(model_path) else create_model(num_classes, image_size=image_size, channels=channels)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adadelta(),\n",
    "        loss=categorical_crossentropy,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(train_images.shape)\n",
    "\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(test_images, test_labels)\n",
    "    )\n",
    "\n",
    "    model.save(model_path)\n",
    "\n",
    "    score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print('Test score   : {:>.4f}'.format(score[0]))\n",
    "    print('Test accuracy: {:>.4f}'.format(score[1]))\n",
    "\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    datasets_path,\n",
    "    model_path,\n",
    "    image_size=image_size,\n",
    "    channels=3,\n",
    "    test_size=0.1,\n",
    "    batch_size=2000,\n",
    "    epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size枚毎学習し、epochs週学習する\n",
    "# 10分程度で2分類80%行ければ良い感じ?\n",
    "# 2度目も同じmodel使って更新するので何度実行しても大丈夫\n",
    "# 2度目実行するとtrain_test_splitで毎回ランダムにテストデータが入れ替わるので厳密にはTest accuracyは嘘になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = get_normalized_image('volume/images/0/0.png', image_size=image_size)\n",
    "model = load_model(model_path)\n",
    "results = model.predict(np.array([image]), verbose=1)\n",
    "\n",
    "labels = search_texts\n",
    "# labels = ['dog', 'cat']\n",
    "\n",
    "predictions = dict(zip(labels, results[0]))\n",
    "for label, score in predictions.items():\n",
    "    print(label, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# capture demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_frame(image_size=28, destroy_callback=None):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, image_size)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, image_size)\n",
    "\n",
    "    def show_frame(frame, zoom=1, text=None, color=(255,255,255), text_size=0.8, frame_name='1'):\n",
    "        size = image_size * zoom\n",
    "        frame = cv2.resize(frame, (size, size))\n",
    "        if(text is not None):\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                text,\n",
    "                (3, size-3),\n",
    "                cv2.FONT_HERSHEY_PLAIN,\n",
    "                text_size,\n",
    "                color\n",
    "            )\n",
    "        cv2.imshow(frame_name, frame)\n",
    "\n",
    "    try:\n",
    "        while(True):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                raise 'destroy'\n",
    "\n",
    "            yield frame, show_frame\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                raise 'destroy'\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        if destroy_callback is not None:\n",
    "            destroy_callback()\n",
    "        cap.release()\n",
    "        cv2.dstroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = load_model(model_path)\n",
    "# for frame, show_frame in generate_frame(image_size=image_size):\n",
    "#     frame = frame.astype(np.float32) / 255.0\n",
    "#     results = model.predict(np.array([frame]), verbose=1)\n",
    "\n",
    "#     # labels = search_texts\n",
    "#     labels = ['dog', 'cat']\n",
    "\n",
    "#     predictions = dict(zip(labels, results[0]))\n",
    "#     predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     show_frame(\n",
    "#         frame,\n",
    "#         zoom=4,\n",
    "#         text='{}:{}'.format(predictions[0], predictions[1]),\n",
    "#         color=(255,255,255),\n",
    "#         text_size=0.8,\n",
    "#         frame_name='1'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "from bottle import Bottle, static_file, url, request, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app = Bottle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.get('/:path#.+#')\n",
    "def get_public(path):\n",
    "    return static_file(path, root='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.get('/')\n",
    "def get_index():\n",
    "    return static_file('index.html', root='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# POSTで画像binaryを渡して分類を判定する。ContentType:multipart/form-data\n",
    "@app.post('/predict/keras')\n",
    "def post_predict_keras():\n",
    "\n",
    "    binary = request.files.get('image').file.read()\n",
    "\n",
    "    # convert binary to image (height any x width any x color channel any)\n",
    "    image = cv2.imdecode(np.fromstring(binary, np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "    # convert image size (28 x 28 x 3)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    predicts = model.predict(np.array([image]))\n",
    "    predicts = predicts.tolist()\n",
    "    results = []\n",
    "    for index, percentage in enumerate(predicts[0]):\n",
    "        results.append({\n",
    "            'label': str(index),\n",
    "            'score': str(percentage)\n",
    "        })\n",
    "    results = sorted(results, key=lambda result: result['score'])\n",
    "\n",
    "    response.content_type = 'application/json'\n",
    "    return dumps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@app.get('/test/keras')\n",
    "def get_test_keras():\n",
    "    return '''\n",
    "<form action=\"/predict/keras\" method=\"post\" enctype=\"multipart/form-data\">\n",
    "    <input type=\"submit\">\n",
    "    <input type=\"file\" name=\"image\">\n",
    "</form>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 停止ボタンで停止\n",
    "app.run(host='0.0.0.0', port=8088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://localhost:8088/test/keras\n",
    "# http://localhost:8088"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
