{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 機械学習ハンズオン\n",
    "\n",
    "機械学習で何か作る際の一連の流れを通して、身近な問題解決手段として選べるようにする。\n",
    "今回は手軽なkerasを利用してCNN(画像分類)を行います。\n",
    "\n",
    "1. データ収集(データベース、データセット、スクレイピング)\n",
    "2. 加工(リサイズ、水増し、画像処理)\n",
    "3. トレーニング(モデル設計、テスト)\n",
    "4. アプリケーションに組み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_texts = ['犬', '猫']\n",
    "datasets_path = 'volume/images'\n",
    "model_path = 'volume/models/model.h5'\n",
    "image_size = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## データ収集\n",
    "\n",
    "まずは分類テーマを決めてその画像を集めます。\n",
    "自社のデータが使えたり、データセットがあれば良いですが、ない場合は自分で収集する必要があります。\n",
    "今回はスクレピングして画像を集めます。\n",
    "\n",
    "スクレピングするライブラリはBeautifulSoupを利用します。\n",
    "下記の例はgithub月間トレンド1位のリポジトリを調べるscriptです。\n",
    "BeautifulSoupでhtmlを解析して、selectでセレクタ指定して要素を取得できます。(:nth-childとかは効かない?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = requests.get('https://github.com/trending?since=monthly').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "element = soup.select('ol.repo-list > li h3 a')[0]\n",
    "print(element.text)\n",
    "print('https://github.com{}'.format(element.attrs['href']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "下記のgoogleで画像検索して保存する関数を使って1ページ20枚、10ページ分の画像を収集。\n",
    "search_textsごとにvolume/images/{index}に保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_scraping(search_texts=[], save_path='.', page=1):\n",
    "    for search_index, search_text in enumerate(search_texts):\n",
    "        \n",
    "        # googleで画像検索\n",
    "        url = 'https://www.google.co.jp/search?q={}&tbm=isch'.format(search_text)\n",
    "        html = requests.get(url).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        for page_index in range(page):\n",
    "            \n",
    "            # 画像を拾う\n",
    "            image_elements = soup.select('#ires a > img')\n",
    "            for element_index, image_element in enumerate(image_elements):\n",
    "                \n",
    "                # src属性から画像をダウンロード\n",
    "                image_url = image_element.attrs['src']\n",
    "                response = requests.get(image_url, stream=True)\n",
    "                dest_path = '{}/{}'.format(save_path, search_index)\n",
    "                if not os.path.isdir(dest_path):\n",
    "                    os.makedirs(dest_path)\n",
    "                file_path = '{}/{}.png'.format(dest_path, (page_index * len(image_elements)) + element_index)\n",
    "                if response.status_code == 200:\n",
    "                    with open(file_path, 'wb') as file:\n",
    "                        response.raw.decode_content = True\n",
    "                        shutil.copyfileobj(response.raw, file)\n",
    "                        print('download: {}'.format(file_path))\n",
    "                        \n",
    "            # 次のページ\n",
    "            page_links = soup.select('#nav tr td a')\n",
    "            next_url = 'https://www.google.co.jp{}'.format(page_links[-1].attrs['href'])\n",
    "            html = requests.get(next_url).text\n",
    "            soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_scraping(search_texts=search_texts, save_path=datasets_path, page=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 加工\n",
    "\n",
    "集めたデータは加工する必要があります。\n",
    "学習する為にはその画像のサイズを統一する必要があり(必要ないモデルもあります)、今回は28x28のカラー画像で統一します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "集めた画像のディレクトリをラベルとして利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dirs(src_path):\n",
    "    listdir = os.listdir(src_path)\n",
    "    return [path for path in listdir if os.path.isdir(os.path.join(src_path, path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_dirs(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "下記の関数を使って保存されている画像に対して28x28のカラー画像に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_resize(src_path, size=28):\n",
    "    dirs = get_dirs(src_path)\n",
    "    for dir_path in dirs:\n",
    "        for image_path in glob.glob('{}/{}/**/*.*'.format(src_path, dir_path), recursive=True):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (size, size))\n",
    "            file_name = os.path.basename(image_path)\n",
    "            save_path = '{}/{}/{}'.format(src_path, dir_path, file_name)\n",
    "            cv2.imwrite(save_path, image)\n",
    "            print('resize: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_resize(datasets_path, size=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "よりよい学習の為にはまず一番にデータをたくさん集める必要があります。\n",
    "また、分類ごとに枚数をなるべく統一した方がいいです。\n",
    "データを集める手法に水増しがあります。\n",
    "\n",
    "これもkerasでImageDataGeneratorという関数が用意されているのでそれを利用します。\n",
    "\n",
    "犬や猫の画像は正面から撮られている事が多いのでx軸回転はなしにしています。\n",
    "携帯など上下関係なく判断したい場合はx軸回転を有効にするなどデータによってパラメータを調整してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, imghdr, time\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generate(src_path, rate=10):\n",
    "    datagen = ImageDataGenerator(\n",
    "        # rotation_range=40, #z軸回転\n",
    "        width_shift_range=0.05, #水平\n",
    "        height_shift_range=0.05, #上下\n",
    "        # shear_range=0.1, #斜め引き伸ばし\n",
    "        zoom_range=0.1, #ズーム\n",
    "        # horizontal_flip=True, #x軸回転\n",
    "        vertical_flip=True, #y軸回転\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    for image_path in glob.glob('{}/**/*.*'.format(src_path), recursive=True):\n",
    "        img = load_img(image_path)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "        generator = datagen.flow(\n",
    "            x,\n",
    "            batch_size=1,\n",
    "            save_to_dir=src_path,\n",
    "            save_prefix='gen',\n",
    "            save_format='png'\n",
    "        )\n",
    "        for _ in range(rate):\n",
    "            generator.next()\n",
    "        print('generate: {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dir_name in get_dirs(datasets_path):\n",
    "    target_path = '{}/{}'.format(datasets_path, dir_name)\n",
    "    image_generate(target_path, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "データの加工手法はたくさんあります。\n",
    "輪郭が重要な意味をもつデータに対してはエッジ検出、マイコンに組み込んで判断速度が重要な問題(自動ブレーキなど)には0か1のバイナリ化するなど。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## トレーニング\n",
    "\n",
    "tensorflow 1.4からkerasが正式に組み込まれたのでtensroflow内蔵のkerasを利用します。\n",
    "kerasはtensorflow(とTheano)のラッパーなのでどちらにせよtensorflowが必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, imghdr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adadelta\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "from tensorflow.python.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.contrib.learn.python.learn.estimators._sklearn import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "画像をcv2で読み込んでarray likeなnumpyオブジェクトに慣れましょう。\n",
    "実態は違いますがarrayっぽく動作し、行列演算の為に最適化されてます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('volume/images/0/0.png')\n",
    "# 正規化 約分のようなもの 0~1などに正規化する\n",
    "normalized_image = image.astype(np.float32) / 255.0\n",
    "print(normalized_image)\n",
    "print(normalized_image.shape)\n",
    "# モデルによってはデータをベクトル化して1次元配列にすることもある\n",
    "vectorize_image = normalized_image.flatten()\n",
    "print(vectorize_image)\n",
    "print(vectorize_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_image(image_path, image_size=56):\n",
    "    \"\"\" 画像を正規化する\n",
    "    @param\n",
    "        images_path         画像パス\n",
    "        image_size          画像の1辺のpixel数\n",
    "    @return\n",
    "        normalized_image    正規化された画像\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (image_size, image_size))\n",
    "    normalized_image = image.astype(np.float32) / 255.0\n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "画像データは28x28x3です。\n",
    "答えラベル(分類)データはone hot表現で用意します。\n",
    "\n",
    "```\n",
    "分類0の場合\n",
    "y = [1,0,0,0,0,0,0]\n",
    "\n",
    "分類5の場合\n",
    "y = [0,0,0,0,0,1,0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_test_splitはscikit-learn(ニューラルネット以外の機械学習ライブラリ)の関数ですが、トレーニングデータとテストデータを良い感じに分けてくれるので利用します。まだcontribですが、tensroflow内蔵です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datasets(datasets_path, test_size=0.1, image_size=56):\n",
    "    \"\"\" 学習用データセットを返す\n",
    "    @param\n",
    "        datasets_path       分類名のフォルダに画像が格納されたデータセットのpath\n",
    "        test_size           テストに使用する画像の割合\n",
    "        image_size          画像サイズ\n",
    "    @return\n",
    "        datasets            tuple(train_images, test_images, train_labels, test_labels)\n",
    "    \"\"\"\n",
    "\n",
    "    labels = get_dirs(datasets_path)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for label in labels:\n",
    "        for image_path in glob.glob('{}/{}/**/*.*'.format(datasets_path, label), recursive=True):\n",
    "            # 画像形式でなければスキップ\n",
    "            if imghdr.what(image_path) is None:\n",
    "                continue\n",
    "\n",
    "            # 正規化したデータをxへ\n",
    "            normalized_image = get_normalized_image(image_path, image_size=image_size)\n",
    "            x.append(normalized_image)\n",
    "\n",
    "            # one hot表現答えラベルをyへ\n",
    "            one_hot = np.zeros(len(labels))\n",
    "            one_hot.put(labels.index(label), 1)\n",
    "            y.append(one_hot)\n",
    "\n",
    "    datasets = train_test_split(\n",
    "        np.array(x),\n",
    "        np.array(y),\n",
    "        test_size=test_size\n",
    "    )\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "各データの形状を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = get_datasets(datasets_path, test_size=0.1, image_size=image_size)\n",
    "train_images, test_images, train_labels, test_labels = datasets\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1番重要なモデル作成です。\n",
    "output_shapeで都度データがどういう形状になっていくか確認できます。\n",
    "\n",
    "- CNNについてhttps://i.stack.imgur.com/jNKSJ.png\n",
    "- 畳み込み 指定サイズごとに切り出してスライド、そのマッチングを元に増やす\n",
    "- プーリング 強い特徴のみ残して減らす\n",
    "- ドロップアウト ニューラルネットワークの線を学習ごとにランダムに切る(過学習抑制) ランダムにできる複数のモデルで学習したような平均化する効果があり、極端にフィットしてしまう事を防ぐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(num_classes, image_size=56, channels=3):\n",
    "    model = Sequential()\n",
    "\n",
    "    input_shape = (image_size, image_size, channels)\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    print(model.input_shape)\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "モデルのインスタンスを作って詳細をconsoleで確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = get_dirs(datasets_path)\n",
    "num_classes = len(labels)\n",
    "channels = 3\n",
    "model = create_model(num_classes, image_size=image_size, channels=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "モデルの詳細を画像に保存できますが tensroflow 1.4.0だと動きませんでした。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create model image (tensorflow 1.4.0だと動かない)\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q. なぜ一気に(None, 28, 28, 3)を(None, 2)にしないのか\n",
    "\n",
    "[参考](https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch02/xor_gate.py)\n",
    "\n",
    "![image](http://hokuts.com/wp-content/uploads/2015/11/perceptron.png)\n",
    "\n",
    "A. XORを作る為\n",
    "\n",
    "上の画像で例えるなら\n",
    "\n",
    "- 丸をノードという\n",
    "- 左側のノードはinputが(28, 28, 3)なので28x28x3=2352個できる\n",
    "- 右側のノードは最終的に(2)にしたいので2個できる\n",
    "- 線はデータ(0~1のRGB値)の流れ\n",
    "- 左側のノードから2352個のデータが右側のノードに渡され、下記のような関数を実行する\n",
    "- 重みやバイアスの値が変わる事によりgate関数はANDやNANDやOR回路の性質に変化する\n",
    "\n",
    "```\n",
    "def gate(*args):\n",
    "    x = np.array(args)\n",
    "    w = np.array([0.5, 0.5, ...]) # len(args)個の重み 学習によって変わっていく値\n",
    "    b = -0.7 # 各ノードに1個存在するバイアス\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "```\n",
    "\n",
    "- 例えばこういう関数に変化する\n",
    "\n",
    "```\n",
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-0.5, -0.5])\n",
    "    b = 0.7\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.2\n",
    "    tmp = np.sum(w*x) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "```\n",
    "\n",
    "- しかしXOR回路が作れない問題がある。\n",
    "- XOR回路はNAND回路とOR回路の値を受け取って自身がAND回路になると表現できるようになる。\n",
    "\n",
    "```\n",
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1, x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y\n",
    "```\n",
    "\n",
    "- 層が少ないと(1層だと確実に)ANDとNANDとOR回路しか作れない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q. なぜXOR回路が必要なのか\n",
    "\n",
    "A. [ここ](http://hokuts.com/2015/12/04/ml3-mlp/)を参考に答えます(ほぼまんまです)\n",
    "\n",
    "\n",
    "\n",
    "##### ORが役立つパターン\n",
    "\n",
    "データ分布イメージ\n",
    "\n",
    "- x_1が男性=0 女性=1\n",
    "- x_2が辛党=0 甘党=1\n",
    "- 今週ケーキ屋に行ったかのデータを元に学習\n",
    "- 性別と甘/辛党のデータを元に来週ケーキ屋に行くかを予測\n",
    "- お菓子産業で成り立っている国で収集したデータ\n",
    "\n",
    "|x_1|x_2|x_1 OR x_2|\n",
    "|---|---|---|\n",
    "|1|1|1|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|0|0|0|\n",
    "\n",
    "![image](http://hokuts.com/wp-content/uploads/2015/12/graph_or.png)\n",
    "\n",
    "##### ANDが役立つパターン\n",
    "\n",
    "データ分布イメージ\n",
    "\n",
    "- x_1が男性=0 女性=1\n",
    "- x_2が辛党=0 甘党=1\n",
    "- 今週ケーキ屋に行ったかのデータを元に学習\n",
    "- 性別と甘/辛党のデータを元に来週ケーキ屋に行くかを予測\n",
    "- 砂糖が高い国で収集したデータの分布\n",
    "\n",
    "|x_1|x_2|x_1 OR x_2|\n",
    "|---|---|---|\n",
    "|1|1|1|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|0|0|0|\n",
    "\n",
    "![image](http://hokuts.com/wp-content/uploads/2015/12/graph_and.png)\n",
    "\n",
    "##### NANDが役立つパターン\n",
    "\n",
    "データ分布イメージ\n",
    "\n",
    "- x_1が男性=0 女性=1\n",
    "- x_2が辛党=0 甘党=1\n",
    "- 今週居酒屋に行ったかのデータを元に学習\n",
    "- 性別と甘/辛党のデータを元に来週居酒屋に行くかを予測\n",
    "\n",
    "|x_1|x_2|x_1 OR x_2|\n",
    "|---|---|---|\n",
    "|1|1|0|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|0|0|1|\n",
    "\n",
    "![image](http://hokuts.com/wp-content/uploads/2015/12/graph_nand.png)\n",
    "\n",
    "##### XORが役立つパターン\n",
    "\n",
    "データ分布イメージ (例に無理が出てきたw)\n",
    "\n",
    "- x_1が男性=0 女性=1\n",
    "- x_2が辛党=0 甘党=1\n",
    "- 今週飲食店に行ったかのデータを元に学習\n",
    "- 性別と甘/辛党のデータを元に来週飲食店に行くかを予測\n",
    "- 辛党男性は居酒屋に、甘党女性はケーキ屋に、それ以外は帰宅する傾向のある国で収集したデータの分布\n",
    "\n",
    "|x_1|x_2|x_1 OR x_2|\n",
    "|---|---|---|\n",
    "|1|1|0|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|0|0|0|\n",
    "\n",
    "![image](http://hokuts.com/wp-content/uploads/2015/12/graph_xor1.png)\n",
    "\n",
    "- ANDとNANDとOR回路のみ(単純パーセプトロン)だと決定境界を線形でしか作れない\n",
    "- XORに分布したデータに対して単純パーセプトロンで解決できない問題があるから"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "下記関数を利用してトレーニングを開始します。\n",
    "batch_size枚を一度に処理し、epochs週トレーニングします。\n",
    "\n",
    "- データにもよりますが、10分程度で2分類80%くらい\n",
    "- 2度目も同じmodel使って更新するので何度実行してもOK\n",
    "- 2度目実行するとtrain_test_splitで毎回ランダムにテストデータが入れ替わるので厳密にはTest accuracyは嘘になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(datasets_path, model_path, image_size=56, channels=3, test_size=0.1, batch_size=1000, epochs=10):\n",
    "\n",
    "    datasets = get_datasets(datasets_path, test_size=test_size, image_size=image_size)\n",
    "    labels = get_dirs(datasets_path)\n",
    "    num_classes = len(labels)\n",
    "    train_images, test_images, train_labels, test_labels = datasets\n",
    "\n",
    "    model = load_model(model_path) if os.path.isfile(model_path) else create_model(num_classes, image_size=image_size, channels=channels)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adadelta(),\n",
    "        loss=categorical_crossentropy,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(train_images.shape)\n",
    "\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(test_images, test_labels)\n",
    "    )\n",
    "\n",
    "    model.save(model_path)\n",
    "\n",
    "    score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print('Test score   : {:>.4f}'.format(score[0]))\n",
    "    print('Test accuracy: {:>.4f}'.format(score[1]))\n",
    "\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    datasets_path,\n",
    "    model_path,\n",
    "    image_size=image_size,\n",
    "    channels=3,\n",
    "    test_size=0.1,\n",
    "    batch_size=2000,\n",
    "    epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "トレーニングした結果を実際に試してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = get_normalized_image('volume/images/0/0.png', image_size=image_size)\n",
    "model = load_model(model_path)\n",
    "results = model.predict(np.array([image]), verbose=1)\n",
    "\n",
    "labels = search_texts\n",
    "# labels = ['dog', 'cat']\n",
    "\n",
    "predictions = dict(zip(labels, results[0]))\n",
    "for label, score in predictions.items():\n",
    "    print(label, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## アプリケーションに組み込み\n",
    "\n",
    "webに組み込んでみます。\n",
    "すごく簡単なbottleというpythonのwebフレームワークを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "from bottle import Bottle, static_file, url, request, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app = Bottle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.get('/:path#.+#')\n",
    "def get_public(path):\n",
    "    return static_file(path, root='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@app.get('/')\n",
    "def get_index():\n",
    "    return static_file('index.html', root='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# POSTで画像binaryを渡して分類を判定する。ContentType:multipart/form-data\n",
    "@app.post('/predict/keras')\n",
    "def post_predict_keras():\n",
    "\n",
    "    binary = request.files.get('image').file.read()\n",
    "\n",
    "    # convert binary to image (height any x width any x color channel any)\n",
    "    image = cv2.imdecode(np.fromstring(binary, np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "    # convert image size (28 x 28 x 3)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    predicts = model.predict(np.array([image]))\n",
    "    predicts = predicts.tolist()\n",
    "    results = []\n",
    "    for index, percentage in enumerate(predicts[0]):\n",
    "        results.append({\n",
    "            'label': str(index),\n",
    "            'score': str(percentage)\n",
    "        })\n",
    "    results = sorted(results, key=lambda result: result['score'])\n",
    "\n",
    "    response.content_type = 'application/json'\n",
    "    return dumps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@app.get('/test/keras')\n",
    "def get_test_keras():\n",
    "    return '''\n",
    "<form action=\"/predict/keras\" method=\"post\" enctype=\"multipart/form-data\">\n",
    "    <input type=\"submit\">\n",
    "    <input type=\"file\" name=\"image\">\n",
    "</form>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 停止ボタンで停止\n",
    "app.run(host='0.0.0.0', port=8088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://localhost:8088/test/keras\n",
    "# http://localhost:8088"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
